{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h1>\n    Information About This Project\n</h1>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p>\nNew York City is home to some of the worlds most renoun and prestigious restaurants with a wide variety of different cuisines, franchises, and fusions of food that one can't find anywhere else.\n<br>\nThe restaurant industry in New York City is thriving, earning <a href=\"https://www.ibisworld.com/industry-trends/market-research-reports/new-york/accommodation-food-services/restaurants-in-new-york.html\">$17 Billion USD in 2018  with 31,061 number of businesses and an annual growth rate of 4.6%</a> and an increased projection of profit and new businesses in 2019. \n<br>\nBecause many New Yorkers and tourists rely on local restaurants it is important to know whether or not the restaurants that we trust are serving us contaminated food. \n<br>\nIn this project I aim to explore the data from NYC Open Data and try to learn more about the health violation reports from the NYDOH and visualize trends in the data.\n<br>\nI also intend on implementing machine learning  techniques to find hotspots of violations in the city, and also create an interactive map where it is possible to find where these restaurants are and which health violations they have been cited for.\n<br>\n</p>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h1>\n    Information About the Data\n</h1>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p> \n    The data set is courtesy of Department of the Health and Mental Hygiene (DOHMH)\n    \n    This dataset includes NYC restaurant and college cafeteria (hereafter, restaurants) inspection results for up to three\n    years prior to the most recent inspection. \n    The purpose is to provide information on recent inspection results. \n    Restaurants that go out of business are removed. Therefore, this dataset is not appropriate for historical analyses of NYC restaurant \n    inspections that compare previous years of data to the current data. \n    In addition, restaurants can choose to go through the adjudication process, i.e., argue their case at an administrative hearing. Restaurants also have\n    appeal rights, and the entire adjudication process from start to finish can take several months.\n    Scores current as of today may be revised due to adjudication in subsequent weeks or months.  The change in scores due to adjudication is\n    another reason why it is not valid to compare current scores to scores from previous years.\n</p>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h1>\n        Description of the Columns:\n</h1>\n<ul>\n    <li>\n        CAMIS: A unique identifier for each restaurant | 10-digit integer, static per restaurant permit.\n   </li>\n    \n   <li>\n        DBA: Restaurant name (Doing Business As) | Public business name, may change at discretion of restaurant owner.\n  </li>\n    \n   <li>      \n        BORO: Which NYC Borough the Restaurant is located.\n  </li>\n    \n   <li>     \n        BUILDING: Which building the restaurant is located.\n  </li>\n    \n   <li>     \n        STREET: Which street the restaurant is located.\n  </li>\n    \n   <li>     \n        ZIPCODE: Which ZipCode the restaurant is located.\n  </li>\n    \n   <li>     \n        PHONE: The phone number of the restaurant | Phone number provided by restaurant owner/manager.\n  </li>\n    \n   <li>     \n        CUISINE DESCRIPTION: Optional field provided by provided by restaurant owner/manager.\n  </li>\n    \n   <li>     \n        INSPECTION DATE: Date of most recent health inspection.\n  </li>\n    \n   <li>     \n        ACTION: Action taken after inspection.\n  </li>\n    \n   <li>     \n        VIOLATION CODE: Code of the violation.\n  </li>\n  \n   <li>    \n        VIOLATION DESCRIPTION: Description of the Violation.\n  </li>\n    \n   <li>     \n        CRITICAL FLAG: Whether or not the violation was critical | Critical violations are those most likely to contribute to foodborne illness.\n  </li>\n    \n   <li>     \n        SCORE: Total score for the inspection.\n  </li>\n    \n   <li>     \n        GRADE: Grade associated with the inspection.\n  </li>\n    \n   <li>     \n        RECORD DATE: Date that the particular record was updated.\n  </li>\n    \n   <li>     \n        Inspection Type: Combination of inspection program and type of inspection performed.\n  </li>\n    \n   <li>    \n        Longitude: Geographical Longitude.\n  </li>\n    \n   <li>     \n        Latitude: Geographical Latitude.\n  </li>\n    \n   <li>     \n        Community Board: Which community board the restaurant is associated with.\n  </li>\n    \n   <li>     \n        Council District: Which Council District the restaurant is associated with.\n  </li>\n    \n   <li>    \n        Census Tract: Census information.\n  </li>\n    \n   <li>    \n        BIN: Building Identification Number\n   </li>\n    \n   <li>     \n        BBL: Borough / Block/  Lot number.\n   </li>\n   <li>     \n        NTA: Neighborhood Tabulation Area\n    </li>\n</ul>\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<H1>Installing Prerequisites</H1>"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import sys\n!{sys.executable} -m pip install folium"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h1>Importing Packages</h1>\n<ul>\n    <li>\n           Folium\n    </li>\n    <li> \n            Matplotlib\n    </li>    \n    <li>\n            Numpy\n    </li>\n    <li>\n            Pandas\n    </li>\n    <li>\n            SciKit-Learn\n    </li>\n</ul>"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Imports\nimport folium as fl\nfrom folium.plugins import FastMarkerCluster\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.preprocessing import StandardScaler"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h1>\n    Importing the Data\n</h1>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<P>\n    After importing the data, the following code will provide some metrics on how many rows and columns are in the data.\n</P"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(\"Loading the data, this may take a few minutes...\")\n\n# Storing the data as a Pandas DataFrame:\n# Since 'CAMIS' is a unique identifying integer, it can be used as the index.\nraw_data = pd.read_csv('https://data.cityofnewyork.us/api/views/43nn-pn8j/rows.csv?accessType=DOWNLOAD', index_col=0)\nraw_data.index.name = 'CAMIS'\nprint(\"The Data was Successfully Loaded!\")\n\n# Checking how many rows and columns are in the data:\nprint(\"The shape of the data: \" + str(raw_data.shape))\nOriginal_Data_Length = len(raw_data)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h1>\n        Cleaning up the Data\n</h1>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p>\n    The first step of data cleanup for this specific data will be dropping columns that are not necessary for the scope of this project.\n</p>"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Storing unnecessary column headers into a list:\nUnnecessary_Columns = ['NTA', 'BBL', 'BIN', 'Census Tract', 'GRADE DATE', 'Council District', 'INSPECTION TYPE', 'BUILDING','STREET', 'ACTION', 'PHONE', 'RECORD DATE', 'Community Board', 'INSPECTION DATE', 'NTA', 'Council District']\n\n# Dropping the unnecessary columns:\ntry:\n    raw_data.drop(\n            Unnecessary_Columns,\n            axis=1, \n            inplace=True\n    )\n    print(\"The columns: \" + str(Unnecessary_Columns) + \" have been dropped successfully.\" )\n    \n# If a KeyError is thrown it means that this block of code was already executed and thus the columns cannot be dropped again.\nexcept(KeyError):\n    print(\"The columns have already been dropped.\")  "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p>\n    Since the remaining columns are necessary for the scope of this project, the remaining <b>missing values</b> will be dropped.\n    <br>\n</p>\n\n<p>\n    It is hard to compare and analyze data that is nonexistent, therefore it is imperative to delete records with empty values.\n<br>\n    The following code will check each column and see if there are any missing values in them.\n<br>\n    <B>False</B> = N many values in the column were not empty.\n    \n<br>\n    <B>True</B> = N many values in the column were empty.\n</p>"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Missing_Values = raw_data.isnull()\n        \nfor Column_Header in Missing_Values.columns.values.tolist():\n    print('Column: ' + Column_Header)\n    print(str(Missing_Values[Column_Header].value_counts()))\n    print()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<P>\n    Since there are a lot of empty values in 'GRADE' and 'DBA', it is not critical to remove the entire row for those two categorical variables, therefore they will be replaced to 'N/A' and 'N' respectively.\n<BR>\n    'N/A' in DBA represents none available, and 'N' in GRADE represents 'Not Yet Graded' which is consistent with the already existing data in the DataFrame.\n</P>"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Grades that are blank can be replaced with an 'N' or not graded yet\nraw_data['GRADE'].replace(np.NaN, 'N', inplace=True)\n\n# Restaurants that are missing their name can be replaced with N/A\nraw_data['DBA'].replace(np.NaN, 'N/A', inplace=True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "raw_data.dropna(inplace=True)\nprint('The length of the data before dropping null values: ' + str(len(raw_data)))\nprint('The length of the data after dropping null values: ' + str(Original_Data_Length - len(raw_data)))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p>\n    Now that the missing values have been dropped, the remaining columns are going to have their data types checked to ensure they make sense.\n</p>"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(raw_data.info())"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p>\n    The ZIPCODE column should be of an int64 datatype, so this will need to be fixed. It does not make sense to have a decimal value within the context of a zipcode.\n    <br>\n    Also, the DBA and VIOLATION DESCRIPTION have to be cast as object as well. (Some values were picked up as integers in the next cell.)\n</p>"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Since it is impossible to convert a None (null) datatype to a Float64, empty records must be dropped.\nraw_data['ZIPCODE'].dropna(inplace=True, axis=0)\nraw_data['ZIPCODE'] = raw_data['ZIPCODE'].astype('int64')\nraw_data.astype({'ZIPCODE': 'int32', 'VIOLATION DESCRIPTION' : 'object', 'DBA' : 'object'}).dtypes\n\nprint(\"The data type of the ZIPCODE column is: \" + str(raw_data['ZIPCODE'].dtype))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p>\n    Since there are some rather long Cuisine Descriptions it is necessary to trim their length in order to graph them without having their descriptions dominate the white space of the graph\n<br>\n    To achieve this, the description will be reduced to just the first word.\n</p>"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Going through every Cuisine Description and reducing it to the first word:\nraw_data['CUISINE DESCRIPTION'] = raw_data['CUISINE DESCRIPTION'].apply(lambda x : x.split()[0].strip())\nprint(\"The cuisine types after shortening them:\")\nprint(raw_data['CUISINE DESCRIPTION'].unique())"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h1>\n    Data Exploration\n</h1>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p>\n    Now that the data has been cleaned, there is a lot of valuable information that can be retrieved from the data set to learn more about the health violations that have been reported against the restaurants in New York City.\n    <br>\n    Since every record pertains to a specific violation, this can be used to gather insights such as how many violations were in each borough, how many violations were deemed 'critical' (most likely to cause illness)\n    <br>\n    and which violations are the most common.\n</p>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p>\n    Which cuisines have the most health violations?\n</p>"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Getting the value count of each cuisine description and plotting it:\nraw_data['CUISINE DESCRIPTION'].value_counts(ascending=False).head(20).plot(\n    figsize=(20, 10),\n    kind='barh', \n)\n\nplt.ylabel('Cuisine Description')\nplt.xlabel('Total Number of Violations')\nplt.title('Trend of the Top Fifteen Restaurant Cuisines and Their Respective Violation Frequency')\nplt.show()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p>\nIt is evident that American restaurants have a significant more health violations than the other cuisine types. But just looking at the amount of violations is not enough to make any conclusions without also analyzing some  other metrics as well.\n</p>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h3>\n    Which organizations have the most health violations?\n</h3>"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": false
            },
            "outputs": [],
            "source": "print(\"Organizations with the most health violations:\") \nprint()\nprint(raw_data['DBA'].value_counts(ascending=False).head(20))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p>\n    Although these are organizations, since they have many different locations in the city, it is unfair to consider them worse offenders due to the fact that their number of violations is skewed by virtue of having multiple stores, which begs the question:\n    <br>\n</p>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n<h3>Which specific restaurants recieved the most health violations?</h3>\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "raw_data['Number_of_Violations'] = raw_data.index.value_counts()\n\nRestaurant_Violations = raw_data[raw_data.columns].sort_values(by='Number_of_Violations', ascending=False).drop_duplicates(keep='first')\nMost_Violations = raw_data[['DBA','CUISINE DESCRIPTION','Number_of_Violations']].sort_values(by='Number_of_Violations', ascending=False).drop_duplicates(keep='first')\nMost_Violations.head(15)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p>\n    When the data is changed to represent the amount of violations per store, the data tells a different story. \n    <br>\n    The following graph details the <b> proportion</b> of cuisine descriptions in the top 20 restaurants with the most violations:\n</p>"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Top_20_Violation_Restaurants = Most_Violations.head(50)\nTop_20_Violation_Restaurants['CUISINE DESCRIPTION'].value_counts(ascending=False).plot(\n    figsize=(20, 10),\n    kind='barh', \n)\nplt.ylabel('Cuisine Description')\nplt.xlabel('Total Number of Restaurants (Top 50 Most Violations)')\nplt.title('Trend of the Top Fifty Restaurant Cuisines(By Number of Violations) and Their Respective Violation Proportion')\nplt.show()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p>\n    An interesting bit of information would be to determine exactly what the mean grade is among restaurants after inspection.\n    <br>\n    Since the grade is a letter grade in the form of A, B, C, it is critical to convert these scores into numerical grades, and then form an average.\n    <br>\n    Due to the 'N' category representing a 'not graded yet', those records will be ignored.\n    <br>\n    <br>\n    what I hope to achieve by doing this is to see how many restaurants have recieved a grade of 'A' despite having more than 13 violations:\n</p>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p>\n    The New York Department of Health's grade breakdown is as follows:\n</p>    \n    <ul>\n        <li>\n            \"A\" grade: 0 to 13 points for sanitary violations (Labeled as 3.0 above)\n        </li>\n        <li>\n            \"B\" grade: 14 to 27 points for sanitary violations (Labeled as 2.0 above)\n         </li>    \n         <li>\n            \"C\" grade: 28 or more points for sanitary violations (Labeled as 1.0 above)\n        </li>\n   </ul>\n             <a href=\"https://a816-health.nyc.gov/ABCEatsRestaurants/#/faq\">As cited in the  New York City Department of Health\n            </a>\n         <br>\n         <br>\n<p>\n    By this metric of looking at pure violations, it is evident based on the data that the majority of violation reports have recieved a grade of 'A', but it also shows that there are a bevy of violations which have recieved poor grades after inspection.\n    However it is important to see the big picture and find out which violations are most common, and how many violations are flagged as critical, meaning they have an increased risk of providing health related illness.\n</p>"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Converting categorical data into numerical data:\nRestaurant_Violations['Numerical_Grades'] = Restaurant_Violations.GRADE.map({'A': 3, 'B': 2, 'C': 1})\n#Getting the mean:\nMean_Grade = Restaurant_Violations['Numerical_Grades'].mean()\n\n\n# Finding out the distribution of grades\nprint(\"The distribution of grades:\")\nprint(Restaurant_Violations['Numerical_Grades'].value_counts())\nprint()\n\n# Printing the mean:\nprint(\"The mean inspection grade: \" + str(Mean_Grade))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p>\n    One other view of the information about grade is by using the score column instead.\n    The score column is a numerical grade which represents the score that the restaurant recieved for every inspection.\n</p>"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Score_Bins = np.linspace(0, max(Restaurant_Violations['SCORE']), 4)\nBin_Names = [\"Low:\", \"Medium: \", \"High: \"]\nRestaurant_Violations['Binned_Scores'] = pd.cut(Restaurant_Violations['SCORE'], Score_Bins, labels=Bin_Names, include_lowest=True)\nprint(Restaurant_Violations['Binned_Scores'].value_counts(ascending=False))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p>\n    Now that we know the number of violations, information regarding the  grades associated to New York Department of Health inspections, and the number of violations per cuisine type, Let's see \n</p>\n<br"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "List_Of_Violations = Restaurant_Violations['VIOLATION CODE'].unique()\nprint(\"A list of the different violation codes in the data: \")\nprint(List_Of_Violations)\nprint()\nprint()\nprint(\"Health codes and their associated description:\")\nViolation_Code_Description_sr = Restaurant_Violations[['VIOLATION CODE', 'VIOLATION DESCRIPTION']].apply(lambda x : ': '.join(x), axis=1)\nprint()\nprint(Violation_Code_Description_sr.unique())"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p>\n    More information about the specific health codes may be found on nyc.gov at the following link.\n    <a href=\"https://www1.nyc.gov/assets/doh/downloads/pdf/rii/ri-violation-penalty.pdf\">Health Violation Codes: New York Department of Health\n    </a>\n</p>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p>\n    Some of the health violation codes are particularly atrocious, involving rodents, roaches, and other pests.\n    it would be interesting to see how many restaurants have these types of violations, and where they are:\n</p>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h3>\n    How many restaurants have violations relating to pests?\n</h3>"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Pest_Mask = ['04N', '04L', '08A', '04M', '04K']\n\nPest_DF = Restaurant_Violations.loc[Restaurant_Violations['VIOLATION CODE'].isin(Pest_Mask)]\nprint(\"The number of restaurants with violations relating to pests is: \" + str(Pest_DF['Number_of_Violations'].count()))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h3>\n    Which restaurants have the most violations relating to pests?\n</h3>"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Pest_DF['Number_of_Pest_Violations'] = Pest_DF.index.value_counts()\nPest_DF_Most_Violations = Pest_DF[['DBA','CUISINE DESCRIPTION','Number_of_Pest_Violations']].sort_values(by='Number_of_Pest_Violations', ascending=False).drop_duplicates(subset='DBA')\nPest_DF_Most_Violations.head(50)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h3>\n    Which cuisine types have the most violations relating to pests?\n</h3>"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "Pest_DF_Most_Violations['CUISINE DESCRIPTION'].value_counts().head(25).plot(kind='bar', figsize=(20,10))\nplt.title('Number of Pest Violation by Cuisine Type')\nplt.xlabel('Cuisine Description')\nplt.ylabel('Number of Violations')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h1>\n    Visualizing the Data With an Interactive Map\n</h1>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p>\n    Because it is hard to visualize what this data means in the real world, it is necessary to construct a map with all of the data points of the health violation data. \n    <br>\n    What this allows us to do is see exactly where these violations are, and which restaurants they belong to.\n    <br>\n    In addition to graphing them, the number of violations of each restaurant are appended to the data point to display the restaurant.\n    <br>\n        Due to memory limitations, only restaurants with violations >= 14  therefore A full view of the dataset can be found at the following link: <br>\n        <a href=\"https://webpage.pace.edu/db19786n/NYC_MAP.html\">Map of NYC with Every Violation as a Data Point</a>\n    </b>\n    It may take a couple of minutes to load, as the HTML file is rather large.\n</p>"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# This block of code will set a temporary index to the dataframe to drop multiple violations for the same restaurant (we only need one datapoint per restaurant)\nShortened_DF = Restaurant_Violations.reset_index().drop_duplicates(subset='CAMIS', keep='first').set_index('CAMIS')\nShortened_DF = Shortened_DF.loc[Shortened_DF['Number_of_Violations'] >= 14]\nShortened_DF['Number_of_Violations'] = Shortened_DF['Number_of_Violations'].astype('object')\nShortened_DF['Number_of_Violations'].dtype\nShortened_DF['DBA_Number_of_Violations'] = Shortened_DF[['DBA', 'Number_of_Violations']].apply(lambda x : ' | Health Violations: '.join(map(str, x)), axis=1)\n\n# How many rows and columns after reshaping the data:\nprint(Shortened_DF.shape)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h1>\n    Map of Restaurants with over 14 Health Violations\n</h1>"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": false
            },
            "outputs": [],
            "source": "def EncodeMap(DataFrame, FoliumMap, DataFrame_Column, color):\n    callback = ('function (row) {'\n                'var marker = L.marker(new L.LatLng(row[0], row[1]), {color: \"' + color + '\"});'\n                                                                                          'var icon = L.AwesomeMarkers.icon({'\n                                                                                          \"markerColor: '\" + color + \"',\"\n                                                                                                                     \"prefix: '',\"\n                                                                                                                     \"extraClasses: 'fa-rotate-0'\"\n                                                                                                                     '});'\n                                                                                                                     'marker.setIcon(icon);'\n                                                                                                                     \"var popup = L.popup({maxWidth: '500'});\"\n                                                                                                                     \"const display_text = {text: row[2]};\"\n                                                                                                                     \"var Popup_Text = $(`<div id='mytext' class='display_text' style='width: 100.0%; height: 100.0%;'> ${display_text.text}</div>`)[0];\"\n                                                                                                                     \"popup.setContent(Popup_Text);\"\n                                                                                                                     \"marker.bindPopup(popup);\"\n                                                                                                                     'return marker};')\n\n    # Add Geolocation marker to cluster:\n    FoliumMap.add_child(\n        FastMarkerCluster(\n            DataFrame[['Latitude', 'Longitude', DataFrame_Column]].values.tolist(), callback=callback\n        )\n    )\n    return FoliumMap\n   \nNYC_Cluster_Map = fl.Map(location=[40.730610, -73.935242],\n                 zoom_start=12,\n                 tiles='OpenStreetMap'\n                )\n\nEncodeMap(Shortened_DF, NYC_Cluster_Map,'DBA_Number_of_Violations', 'red')\nNYC_Cluster_Map"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h1>\n    Map of Restaurants With Pest Related Vioaltions\n</h1>"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Creating a column to visualize the DBA of the restaurant + number of pest violations on the geographical data point:\nPest_DF['DBA_Number_of_Pest_Violations'] = Pest_DF[['DBA', 'Number_of_Pest_Violations']].apply(lambda x : ' | Pest Violations: '.join(map(str, x)), axis=1)\n# Dropping multiple reports for each restaurant: (only one point per restaurant is required)\nPest_DF = Pest_DF.reset_index().drop_duplicates(subset='CAMIS', keep='first').set_index('CAMIS')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "NYC_PEST_MAP = fl.Map(location=[40.730610, -73.935242],\n                 zoom_start=12,\n                 tiles='OpenStreetMap'\n                )\nEncodeMap(Pest_DF, NYC_PEST_MAP, 'DBA_Number_of_Pest_Violations', 'gray')\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h1>\n    DBSCAN (Density Based Spatial Clustering of Applications with Noise)\n</h1>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p>\n    Because there is such a vast amount of  \n    DBSCAN is an unsupervised machine learning algorithm which analyzes points of data and clusters them together based on the following parameters:\n    <br>\n            Epsilon: Euclidean Distance between the points. (Euclidean Distance is the default algorithm)\n    <br>\n            min_samples: Number of samples that the algorithm will cluster together.\n    <br>\n    <br>\n            Some of the advantages of DBSCAN are:\n    <ul>\n        <li>\n            DBSCAN is efficient in comparison to other algorithms when dealing with large sample sizes (Worst case O(N\u00b2)\n        </li>\n        <li>\n             The number of clusters are not required to be known beforehand.\n        </li>\n        <li>\n            DBSCAN can form arbitrary (unusual) shapes.\n        </li>\n    </ul>\n    As with any algorithm, there are a few drawbacks to DBSCAN as well:\n       <ul>\n        <li>\n            It relies on the distance of the points, which is not necessarily the best indicated for 'similar' samples.\n        </li>\n        <li>\n             DBSCAN is very sensitive to its parameters. If incorrectly set, they can produce poor clusters.\n        </li>\n        <li>\n            DBSCAN can run into issues when dealing with clusters with different distances.\n        </li>\n    </ul>\n</p>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p>\n    The first step for creating the model is getting the coordinates of all individual restaurants, and putting them into a matrix.\n</p>"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Creating a feature matrix and setting the parameters for DBSCAN:\nDBS_DF = Shortened_DF\nCoordinates_df = pd.DataFrame(DBS_DF[['Latitude', 'Longitude']])\nx = DBS_DF['Longitude'].values.tolist()\ny = DBS_DF['Latitude'].values.tolist()\nFeature_Matrix = np.array(np.column_stack((x, y)))                                    \nprint(Feature_Matrix)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now that the feature matrix is constructed, it can be used to train the DBSCAN model with the parameters epsilon and min_samples:"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Training the model:\nDBS = DBSCAN(eps=0.010, min_samples=100, n_jobs=-1).fit(Feature_Matrix)\nDBS_Labels = DBS.labels_\nprint(DBS)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p>\n    Now that the model has been trained, it can be used to find the number of clusters based on the samples using the model:\n</p>"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Differentiating clustered samples and outliers\nUnique_Labels = set(DBS_Labels)\nNumber_of_Clusters = len(Unique_Labels) - (1 if -1 in DBS_Labels else 0)\nprint(\"There are: \" + str(Number_of_Clusters) + \" clusters in the data set.\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "figure = plt.figure(figsize=(15, 15))\nplt.scatter(Feature_Matrix[:, 0], Feature_Matrix[:, 1], c=DBS_Labels, s=3)\nplt.title('DBSCAN Clustering of Restaurants With Over 14 Violations.' '\\n' 'Number of Clusters: ' + str(Number_of_Clusters), fontsize=20)\nplt.xlabel('Latitude',  fontsize=20)\nplt.ylabel('Longitude',  fontsize=20)\nplt.show()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p>\n    Based on the results from the DBSCAN clustering, it is evident the highest density clusters are:\n        <ul>\n            <li>\n                Lower Manhattan - Midtown\n            </li>\n            <li>\n                Washington Heights\n            </li>\n            <li>\n                Astoria \n            </li>\n            <li>\n                Williamsburg / Green Point\n            </li>\n            <li>\n                Carol Gardens\n            </li>\n            <li>\n                Bay Ridge\n            </li>\n            <li>\n                Jackson Heights\n            </li>\n            <li>\n                Flushing\n            </li>\n            <li>\n                Central Bronx\n            </li>\n        </ul>\n        <br>\n            This means that these are high concentrations of restaurants with over 14 food violations, which is reasonable considering these are all popular food hubs in New York City. These areas contain a high volume of restaurants, and thus would also contain a high volume of restaurant violations as well.         \n</p>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h1>\n    Conclusions\n</h1>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<p>\n    Although there were a lot of violations reported, it appears that the New York Department of Health is doing their part in preventing food related illness. \n    <br>\n    Despite this, there is an alarming amount of restaurants operating with a history of pests, rodents, and other atrocious violations scattered around the city. \n    <br>\n    What is even more shocking about the data is that some restaurants have a history of dozens of pest related health violations and these restaurants are still allowed to operate, and have high ratings on popular review websites.\n    <br>\n    Due to the sheer number of restaurants with violations it would be impossible to avoid all of them, therefore it is important to do proper research before eating somewhere untrustworthy.\n</p>"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}